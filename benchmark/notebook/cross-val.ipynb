{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ceeae8f-ef7d-4b00-9f31-26785721d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import pathlib\n",
    "import numpy\n",
    "import collections\n",
    "import abc\n",
    "import numpy.typing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c362153-d4f8-407c-8714-0d123962ea5d",
   "metadata": {},
   "source": [
    "# Generate data (not needed if loading data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46abe58-2987-421e-9078-65a1752aeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "327b2da9-fa4b-4e04-8a1c-25cec2322f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import functools\n",
    "from typing import Mapping, Callable\n",
    "from util import flatten1\n",
    "from prov_collectors import PROV_COLLECTORS\n",
    "from workloads import WORKLOADS\n",
    "import operator\n",
    "\n",
    "rel_qois = [\"cputime\", \"walltime\", \"memory\"]\n",
    "abs_qois = [\"storage\", \"n_ops\", \"n_unique_files\"]\n",
    "output = pathlib.Path(\"output\")\n",
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "1c8cd970-9dee-409b-93cc-e073e1df0f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                               | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Construct DataFrame: running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 4920/5000 [03:46<00:02, 32.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Construct DataFrame > setup postmark: running\n",
      " > Construct DataFrame > setup postmark: 0.0s\n",
      " > Construct DataFrame > setup fsatrace: running\n",
      " > Construct DataFrame > setup fsatrace: 0.0s\n",
      " > Construct DataFrame > run postmark in fsatrace: running\n",
      " > Construct DataFrame > run postmark in fsatrace: 0.0s (err)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:charmonium.logger: > Construct DataFrame > run postmark in fsatrace: 0.0s (err)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Construct DataFrame: 226.9s (err)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:charmonium.logger: > Construct DataFrame: 226.9s (err)\n"
     ]
    },
    {
     "ename": "DBusBaseError",
     "evalue": "[err -123]: Could not open a bus to DBus\nThis is DBusBaseError, a base error for DBus (i bet you did not see that coming) if you need a special error, enhance pystemd.sysdexc module!.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDBusBaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[450], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m ignore_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m rerun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkloads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrerun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrerun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/box/prov/benchmark/experiment.py:54\u001b[0m, in \u001b[0;36mget_results\u001b[0;34m(prov_collectors, workloads, iterations, seed, ignore_failures, rerun)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expect_type(pandas\u001b[38;5;241m.\u001b[39mDataFrame, pickle\u001b[38;5;241m.\u001b[39mloads(key\u001b[38;5;241m.\u001b[39mread_bytes()))\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprov_collectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkloads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbig_temp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrerun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     key\u001b[38;5;241m.\u001b[39mwrite_bytes(pickle\u001b[38;5;241m.\u001b[39mdumps(results_df))\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_df\n",
      "File \u001b[0;32m~/box/prov/benchmark/experiment.py:104\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(prov_collectors, workloads, cache_dir, big_temp_dir, iterations, size, seed, ignore_failures, rerun)\u001b[0m\n\u001b[1;32m     94\u001b[0m result_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     95\u001b[0m     (prov_collector, workload, run_one_experiment_cached(\n\u001b[1;32m     96\u001b[0m         cache_dir, iteration, prov_collector, workload,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration, prov_collector, workload \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(inputs)\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ch_time_block\u001b[38;5;241m.\u001b[39mctx(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstruct DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    103\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 104\u001b[0m         \u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprov_collector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollector_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprov_collector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollector_submethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprov_collector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworkload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworkload_kind\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcputime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcputime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwalltime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalltime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovenance_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_ops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_unique_files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mop_type_counts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprov_collector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult_list\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_method\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_submethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_submethod\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    132\u001b[0m         })\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_df\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/pandas/core/frame.py:2315\u001b[0m, in \u001b[0;36mDataFrame.from_records\u001b[0;34m(cls, data, index, exclude, columns, coerce_float, nrows)\u001b[0m\n\u001b[1;32m   2312\u001b[0m values \u001b[38;5;241m=\u001b[39m [first_row]\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nrows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2315\u001b[0m     values \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m   2316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2317\u001b[0m     values\u001b[38;5;241m.\u001b[39mextend(itertools\u001b[38;5;241m.\u001b[39mislice(data, nrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/box/prov/benchmark/experiment.py:104\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m result_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     95\u001b[0m     (prov_collector, workload, run_one_experiment_cached(\n\u001b[1;32m     96\u001b[0m         cache_dir, iteration, prov_collector, workload,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration, prov_collector, workload \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(inputs)\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ch_time_block\u001b[38;5;241m.\u001b[39mctx(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstruct DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    103\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 104\u001b[0m         pandas\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\n\u001b[1;32m    105\u001b[0m             {\n\u001b[1;32m    106\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector\u001b[39m\u001b[38;5;124m\"\u001b[39m: prov_collector\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    107\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: prov_collector\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    108\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_submethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: prov_collector\u001b[38;5;241m.\u001b[39msubmethod,\n\u001b[1;32m    109\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload\u001b[39m\u001b[38;5;124m\"\u001b[39m: workload\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    110\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m: workload\u001b[38;5;241m.\u001b[39mkind,\n\u001b[1;32m    111\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcputime\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39mcputime,\n\u001b[1;32m    112\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwalltime\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39mwalltime,\n\u001b[1;32m    113\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39mmemory,\n\u001b[1;32m    114\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39mprovenance_size,\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_ops\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(stats\u001b[38;5;241m.\u001b[39moperations),\n\u001b[1;32m    116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_unique_files\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_unique(itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    117\u001b[0m                     (op\u001b[38;5;241m.\u001b[39mtarget0 \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m stats\u001b[38;5;241m.\u001b[39moperations),\n\u001b[1;32m    118\u001b[0m                     (op\u001b[38;5;241m.\u001b[39mtarget1 \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m stats\u001b[38;5;241m.\u001b[39moperations),\n\u001b[1;32m    119\u001b[0m                 )),\n\u001b[1;32m    120\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop_type_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m: collections\u001b[38;5;241m.\u001b[39mCounter(\n\u001b[1;32m    121\u001b[0m                     op\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m stats\u001b[38;5;241m.\u001b[39moperations\n\u001b[1;32m    122\u001b[0m                 ),\n\u001b[1;32m    123\u001b[0m             }\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m prov_collector, workload, stats \u001b[38;5;129;01min\u001b[39;00m result_list\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_method\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_submethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollector_submethod\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m df: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkload_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    132\u001b[0m         })\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_df\n",
      "File \u001b[0;32m~/box/prov/benchmark/experiment.py:95\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     92\u001b[0m work_dir\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(inputs)\n\u001b[1;32m     94\u001b[0m result_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 95\u001b[0m     (prov_collector, workload, \u001b[43mrun_one_experiment_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprov_collector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrerun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration, prov_collector, workload \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(inputs)\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ch_time_block\u001b[38;5;241m.\u001b[39mctx(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstruct DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    103\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    104\u001b[0m         pandas\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\n\u001b[1;32m    105\u001b[0m             {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m         })\n\u001b[1;32m    133\u001b[0m     )\n",
      "File \u001b[0;32m~/box/prov/benchmark/experiment.py:168\u001b[0m, in \u001b[0;36mrun_one_experiment_cached\u001b[0;34m(cache_dir, iteration, prov_collector, workload, work_dir, log_dir, temp_dir, artifacts_dir, size, ignore_failures, rerun)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     delete_children(temp_dir)\n\u001b[0;32m--> 168\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43mrun_one_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprov_collector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     cache_dir\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    173\u001b[0m     key\u001b[38;5;241m.\u001b[39mwrite_bytes(pickle\u001b[38;5;241m.\u001b[39mdumps(stats))\n",
      "File \u001b[0;32m~/box/prov/benchmark/experiment.py:229\u001b[0m, in \u001b[0;36mrun_one_experiment\u001b[0;34m(iteration, prov_collector, workload, work_dir, log_dir, temp_dir, artifacts_dir, size, ignore_failures)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ch_time_block\u001b[38;5;241m.\u001b[39mctx(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworkload\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprov_collector\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    219\u001b[0m     full_env \u001b[38;5;241m=\u001b[39m merge_env_vars(\n\u001b[1;32m    220\u001b[0m         {\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(result_lib),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m         env,\n\u001b[1;32m    228\u001b[0m     )\n\u001b[0;32m--> 229\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43mrun_exec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir_modes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDirMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFULL_ACCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDirMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFULL_ACCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDirMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_ONLY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/nix/store\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDirMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_ONLY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnetwork_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_failures \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stats\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SubprocessError(\n\u001b[1;32m    243\u001b[0m         cmd\u001b[38;5;241m=\u001b[39mcmd,\n\u001b[1;32m    244\u001b[0m         env\u001b[38;5;241m=\u001b[39mfull_env,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m         stderr\u001b[38;5;241m=\u001b[39mto_str(stats\u001b[38;5;241m.\u001b[39mstderr),\n\u001b[1;32m    249\u001b[0m     )\n",
      "File \u001b[0;32m~/box/prov/benchmark/run_exec_wrapper.py:106\u001b[0m, in \u001b[0;36mrun_exec\u001b[0;34m(cmd, cwd, env, dir_modes, time_limit, mem_limit, network_access)\u001b[0m\n\u001b[1;32m     91\u001b[0m dir_modes_processed \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m: DirMode\u001b[38;5;241m.\u001b[39mREAD_ONLY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     },\n\u001b[1;32m    103\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# https://github.com/sosy-lab/benchexec/blob/2c56e08d5f0f44b3073f9c82a6c5f166a12b45e7/benchexec/runexecutor.py#L304\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# https://github.com/sosy-lab/benchexec/blob/2c56e08d5f0f44b3073f9c82a6c5f166a12b45e7/benchexec/containerexecutor.py#L297\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m run_executor \u001b[38;5;241m=\u001b[39m \u001b[43mRunExecutor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_namespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# gid=os.getgid(),\u001b[39;49;00m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# uid=os.getuid(),\u001b[39;49;00m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdir_modes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_modes_processed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_system_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_tmpfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m caught_signal_number: Signal \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_executor_stop\u001b[39m(signal_number: Signal, _: types\u001b[38;5;241m.\u001b[39mFrameType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/benchexec/runexecutor.py:335\u001b[0m, in \u001b[0;36mRunExecutor.__init__\u001b[0;34m(self, cleanup_temp_dir, additional_cgroup_subsystems, *args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cgroup_subsystems \u001b[38;5;241m=\u001b[39m additional_cgroup_subsystems\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_energy_measurement \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    332\u001b[0m     intel_cpu_energy\u001b[38;5;241m.\u001b[39mEnergyMeasurement\u001b[38;5;241m.\u001b[39mcreate_if_supported()\n\u001b[1;32m    333\u001b[0m )\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_cgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/benchexec/runexecutor.py:341\u001b[0m, in \u001b[0;36mRunExecutor._init_cgroups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_cgroups\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    This function initializes the cgroups for the limitations and measurements.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcgroups \u001b[38;5;241m=\u001b[39m \u001b[43mCgroups\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     critical_cgroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subsystem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cgroup_subsystems:\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/benchexec/cgroups.py:89\u001b[0m, in \u001b[0;36mCgroups.initialize\u001b[0;34m(allowed_versions)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m version \u001b[38;5;241m==\u001b[39m CGROUPS_V2:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcgroupsv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Cgroups\u001b[38;5;241m.\u001b[39mdummy()\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/benchexec/cgroupsv2.py:112\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(cgroup\u001b[38;5;241m.\u001b[39mget_all_tasks()) \u001b[38;5;241m==\u001b[39m [os\u001b[38;5;241m.\u001b[39mgetpid()]:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# If we are the only process, somebody prepared a cgroup for us. Use it.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# We might be able to relax this check and for example allow child processes,\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# but then we would also have to move them to another cgroup,\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# which might not be a good idea.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBenchExec was started in its own cgroup: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, cgroup)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43m_create_systemd_scope_for_us\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# If we can create a systemd scope for us and move ourselves in it,\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# we have a usable cgroup afterwards.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     cgroup \u001b[38;5;241m=\u001b[39m CgroupsV2\u001b[38;5;241m.\u001b[39mfrom_system()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# No usable cgroup. We might still be able to continue if we actually\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# do not require cgroups for benchmarking. So we do not fail here\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# but return an instance that will on produce an error later.\u001b[39;00m\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/benchexec/cgroupsv2.py:162\u001b[0m, in \u001b[0;36m_create_systemd_scope_for_us\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpystemd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdbusexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DBusFileNotFoundError\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpystemd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msystemd1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Manager, Unit\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DBus(user_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m bus, Manager(bus\u001b[38;5;241m=\u001b[39mbus) \u001b[38;5;28;01mas\u001b[39;00m manager:\n\u001b[1;32m    163\u001b[0m     unit_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# workaround for not declared parameters, remove in the future\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_custom\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIDs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mau\u001b[39m\u001b[38;5;124m\"\u001b[39m, [os\u001b[38;5;241m.\u001b[39mgetpid()]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelegate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    169\u001b[0m     }\n\u001b[1;32m    171\u001b[0m     random_suffix \u001b[38;5;241m=\u001b[39m secrets\u001b[38;5;241m.\u001b[39mtoken_urlsafe(\u001b[38;5;241m8\u001b[39m)\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/pystemd/dbuslib.pyx:287\u001b[0m, in \u001b[0;36mpystemd.dbuslib.DBus.__enter__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/nix/store/fcxqkrbvqb1fc2fmpxvgvk3788m2h3ip-python3-3.10.13-env/lib/python3.10/site-packages/pystemd/dbuslib.pyx:305\u001b[0m, in \u001b[0;36mpystemd.dbuslib.DBus.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDBusBaseError\u001b[0m: [err -123]: Could not open a bus to DBus\nThis is DBusBaseError, a base error for DBus (i bet you did not see that coming) if you need a special error, enhance pystemd.sysdexc module!."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 4920/5000 [04:01<00:02, 32.56it/s]"
     ]
    }
   ],
   "source": [
    "from experiment import get_results\n",
    "from workloads import WORKLOAD_GROUPS\n",
    "from prov_collectors import PROV_COLLECTOR_GROUPS\n",
    "from util import flatten1\n",
    "\n",
    "collectors = list(flatten1([\n",
    "    PROV_COLLECTOR_GROUPS[collector_name]\n",
    "    for collector_name in [\"fast\"]\n",
    "]))\n",
    "workloads = list(flatten1([\n",
    "    WORKLOAD_GROUPS[workload_name]\n",
    "    for workload_name in [\"working\"]\n",
    "]))\n",
    "iterations = 4\n",
    "ignore_failures = True\n",
    "rerun = False\n",
    "df = get_results(\n",
    "    collectors,\n",
    "    workloads,\n",
    "    iterations=iterations,\n",
    "    seed=0,\n",
    "    ignore_failures=ignore_failures,\n",
    "    rerun=rerun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2ebc156-9ed5-4d8c-9209-486a68ca0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agged = (\n",
    "    df\n",
    "    .groupby([\"collector\", \"workload\"], observed=True, as_index=True)\n",
    "    .agg(**{\n",
    "        **{\n",
    "            f\"{qoi}_std\": pandas.NamedAgg(qoi, \"std\")\n",
    "            for qoi in abs_qois + rel_qois\n",
    "        },\n",
    "        **{\n",
    "            f\"{qoi}_mean\": pandas.NamedAgg(qoi, \"mean\")\n",
    "            for qoi in abs_qois + rel_qois\n",
    "        },\n",
    "        **{\n",
    "            f\"{qoi}_low\": pandas.NamedAgg(qoi, lambda data: numpy.percentile(data, 5))\n",
    "            for qoi in abs_qois + rel_qois\n",
    "        },\n",
    "        **{\n",
    "            f\"{qoi}_high\": pandas.NamedAgg(qoi, lambda data: numpy.percentile(data, 95))\n",
    "            for qoi in abs_qois + rel_qois\n",
    "        },\n",
    "        **{\n",
    "            f\"{qoi}_sorted\": pandas.NamedAgg(qoi, lambda data: list(sorted(data)))\n",
    "            for qoi in abs_qois + rel_qois\n",
    "        },\n",
    "        \"op_type_counts_sum\": pandas.NamedAgg(\"op_type_counts\", lambda op_type_freqs: functools.reduce(operator.add, op_type_freqs, collections.Counter())),\n",
    "        \"count\": pandas.NamedAgg(\"walltime\", lambda walltimes: len(walltimes)),\n",
    "    })\n",
    "    .assign(**{\n",
    "        **{\n",
    "            f\"{qoi}_rel\": lambda df, qoi=qoi: df[f\"{qoi}_std\"] / df[f\"{qoi}_mean\"]\n",
    "            for qoi in abs_qois + rel_qois\n",
    "        },\n",
    "        \"rel_slowdown\": lambda df: df[\"walltime_mean\"] / df.loc[\"noprov\"][\"walltime_mean\"],\n",
    "    })\n",
    "    .assign(**{\n",
    "        \"log_rel_slowdown\": lambda df: numpy.log(df[\"rel_slowdown\"]),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726ebf9-f6aa-416c-83bd-258974a82555",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ec984a13-233d-465b-826f-e42f4eb0e5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'newfstatat': 16650554,\n",
       "         'close': 10038172,\n",
       "         'openat': 9253868,\n",
       "         'unlink': 2820321,\n",
       "         'creat': 1267063,\n",
       "         'readlink': 1092232,\n",
       "         'utimensat': 789797,\n",
       "         'exit_group': 261135,\n",
       "         'clone': 256629,\n",
       "         'access': 185192,\n",
       "         'execve': 133982,\n",
       "         'connect': 48001,\n",
       "         'mkdirat': 45008,\n",
       "         'dup2': 21375,\n",
       "         'mkdir': 19360,\n",
       "         'rmdir': 16841,\n",
       "         'clone3': 14702,\n",
       "         'pipe2': 12540,\n",
       "         'rename': 12121,\n",
       "         'exit': 11301,\n",
       "         'chdir': 8444,\n",
       "         'vfork': 4944,\n",
       "         'accept': 2675,\n",
       "         'chmod': 2641,\n",
       "         'fchmod': 2311,\n",
       "         'dup': 2238,\n",
       "         'bind': 2153,\n",
       "         'symlink': 513,\n",
       "         'accept4': 22,\n",
       "         'link': 9,\n",
       "         'ftruncate': 7})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "all_syscalls = collections.Counter()\n",
    "for counter in df[df[\"collector\"] == \"strace\"][\"op_type_counts\"]:\n",
    "    all_syscalls += counter\n",
    "all_syscalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "59cf98ad-fa0d-426c-8810-c17d5ebb9824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'socket': {'accept', 'accept4', 'bind', 'connect'},\n",
       " 'file': {'access',\n",
       "  'chmod',\n",
       "  'fchmod',\n",
       "  'link',\n",
       "  'mkdir',\n",
       "  'mkdirat',\n",
       "  'newfstatat',\n",
       "  'readlink',\n",
       "  'rename',\n",
       "  'rmdir',\n",
       "  'symlink',\n",
       "  'unlink'},\n",
       " 'fd': {'creat', 'open', 'openat'},\n",
       " 'clone': {'clone', 'clone3'},\n",
       " 'fork': {'vfork'},\n",
       " 'exec': {'clone', 'clone3'},\n",
       " 'other': {'chdir',\n",
       "  'close',\n",
       "  'dup',\n",
       "  'dup2',\n",
       "  'execve',\n",
       "  'exit',\n",
       "  'exit_group',\n",
       "  'ftruncate',\n",
       "  'pipe2',\n",
       "  'utimensat'}}"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syscall_groups = {\n",
    "    \"socket\": {\"accept4\", \"connect\", \"bind\", \"accept\"},\n",
    "    \"file\": {\"newfstatat\", \"readlink\", \"access\", \"chmod\", \"fchmod\", \"mkdir\", \"rmdir\", \"mkdirat\", \"rename\", \"unlink\", \"link\", \"symlink\"},\n",
    "    \"fd\": {\"creat\", \"open\", \"openat\"},\n",
    "    \"clone\": {\"clone\", \"clone3\"},\n",
    "    \"fork\": {\"vfork\"},\n",
    "    \"exec\": {\"clone\", \"clone3\"},\n",
    "}\n",
    "syscall_groups[\"other\"] = {\n",
    "    syscall\n",
    "    for syscall in all_syscalls\n",
    "    if not any(syscall in group for group in syscall_groups.values())\n",
    "}\n",
    "syscall_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "9d6af443-1bae-4334-a708-1a8071c25a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'socket': {'accept', 'accept4', 'bind', 'connect'},\n",
       " 'metadata': {'access', 'newfstatat'},\n",
       " 'chmod': {'chmod', 'fchmod'},\n",
       " 'dir': {'link',\n",
       "  'mkdir',\n",
       "  'mkdirat',\n",
       "  'readlink',\n",
       "  'rename',\n",
       "  'rmdir',\n",
       "  'symlink',\n",
       "  'unlink'},\n",
       " 'file': {'creat', 'open', 'openat'},\n",
       " 'exec': {'execve', 'vfork'},\n",
       " 'clone': {'clone', 'clone3'},\n",
       " 'exits': {'exit', 'exit_group'},\n",
       " 'dups': {'dup', 'dup2'},\n",
       " 'other': {'chdir', 'close', 'ftruncate', 'pipe2', 'utimensat'}}"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syscall_groups = {\n",
    "    \"socket\": {\"accept4\", \"connect\", \"bind\", \"accept\"},\n",
    "    \"metadata\": {\"newfstatat\", \"access\"},\n",
    "    \"chmod\": {\"chmod\", \"fchmod\"},\n",
    "    \"dir\": {\"mkdir\", \"rmdir\", \"mkdirat\", \"rename\", \"unlink\", \"link\", \"readlink\", \"symlink\"},\n",
    "    \"file\": {\"creat\", \"open\", \"openat\"},\n",
    "    \"exec\": {\"execve\", \"vfork\"},\n",
    "    \"clone\": {\"clone\", \"clone3\"},\n",
    "    \"exits\": {\"exit\", \"exit_group\"},\n",
    "    \"dups\": {\"dup\", \"dup2\"},\n",
    "}\n",
    "syscall_groups[\"other\"] = {\n",
    "    syscall\n",
    "    for syscall in all_syscalls\n",
    "    if not any(syscall in group for group in syscall_groups.values())\n",
    "}\n",
    "syscall_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "d432149c-4640-4f72-856d-a8663c2d6efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cputime_per_sec</th>\n",
       "      <th>memory_mean</th>\n",
       "      <th>socket_syscalls_per_sec</th>\n",
       "      <th>metadata_syscalls_per_sec</th>\n",
       "      <th>chmod_syscalls_per_sec</th>\n",
       "      <th>dir_syscalls_per_sec</th>\n",
       "      <th>file_syscalls_per_sec</th>\n",
       "      <th>exec_syscalls_per_sec</th>\n",
       "      <th>clone_syscalls_per_sec</th>\n",
       "      <th>exits_syscalls_per_sec</th>\n",
       "      <th>dups_syscalls_per_sec</th>\n",
       "      <th>other_syscalls_per_sec</th>\n",
       "      <th>n_ops_per_sec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workload</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a-data-sci</th>\n",
       "      <td>1.846697</td>\n",
       "      <td>5.019648e+08</td>\n",
       "      <td>1.505072</td>\n",
       "      <td>1822.089894</td>\n",
       "      <td>0.082848</td>\n",
       "      <td>1.491264</td>\n",
       "      <td>722.116985</td>\n",
       "      <td>4.473792</td>\n",
       "      <td>1.242720</td>\n",
       "      <td>1.132256</td>\n",
       "      <td>1.118448</td>\n",
       "      <td>474.014838</td>\n",
       "      <td>3029.268116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archive</th>\n",
       "      <td>0.641795</td>\n",
       "      <td>8.645291e+06</td>\n",
       "      <td>299.254091</td>\n",
       "      <td>122776.062947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41635.028198</td>\n",
       "      <td>75.930143</td>\n",
       "      <td>75.185729</td>\n",
       "      <td>76.178280</td>\n",
       "      <td>0.744413</td>\n",
       "      <td>40435.778592</td>\n",
       "      <td>205374.162394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archive bzip2</th>\n",
       "      <td>1.012189</td>\n",
       "      <td>9.310208e+06</td>\n",
       "      <td>18.078526</td>\n",
       "      <td>3815.702057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1370.741457</td>\n",
       "      <td>8.965373</td>\n",
       "      <td>4.507317</td>\n",
       "      <td>4.605837</td>\n",
       "      <td>7.241263</td>\n",
       "      <td>1267.073177</td>\n",
       "      <td>6496.915007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archive gzip</th>\n",
       "      <td>1.026436</td>\n",
       "      <td>3.751936e+06</td>\n",
       "      <td>85.001375</td>\n",
       "      <td>14739.397643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5254.341122</td>\n",
       "      <td>40.895011</td>\n",
       "      <td>17.165106</td>\n",
       "      <td>17.278782</td>\n",
       "      <td>36.149030</td>\n",
       "      <td>4924.566478</td>\n",
       "      <td>25114.794549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archive pbzip2</th>\n",
       "      <td>5.782112</td>\n",
       "      <td>5.392111e+07</td>\n",
       "      <td>53.239038</td>\n",
       "      <td>10807.663452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3970.368904</td>\n",
       "      <td>25.335396</td>\n",
       "      <td>81.420327</td>\n",
       "      <td>84.890930</td>\n",
       "      <td>19.851845</td>\n",
       "      <td>3614.632180</td>\n",
       "      <td>18657.402070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unarchive bzip2</th>\n",
       "      <td>1.085411</td>\n",
       "      <td>1.425408e+07</td>\n",
       "      <td>26.959380</td>\n",
       "      <td>3829.953241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>201.189403</td>\n",
       "      <td>3604.576401</td>\n",
       "      <td>13.569107</td>\n",
       "      <td>13.479690</td>\n",
       "      <td>13.703234</td>\n",
       "      <td>13.502044</td>\n",
       "      <td>7011.249493</td>\n",
       "      <td>14728.181994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unarchive gzip</th>\n",
       "      <td>1.000682</td>\n",
       "      <td>1.138278e+07</td>\n",
       "      <td>116.492802</td>\n",
       "      <td>11320.507291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.528912</td>\n",
       "      <td>10481.126988</td>\n",
       "      <td>58.439910</td>\n",
       "      <td>38.895437</td>\n",
       "      <td>39.475966</td>\n",
       "      <td>58.246401</td>\n",
       "      <td>20418.685404</td>\n",
       "      <td>43112.399111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unarchive pbzip2</th>\n",
       "      <td>3.238676</td>\n",
       "      <td>4.018859e+07</td>\n",
       "      <td>52.587740</td>\n",
       "      <td>6911.684236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>356.709607</td>\n",
       "      <td>6608.789943</td>\n",
       "      <td>23.997116</td>\n",
       "      <td>154.555684</td>\n",
       "      <td>198.471198</td>\n",
       "      <td>23.917918</td>\n",
       "      <td>12540.948330</td>\n",
       "      <td>26871.661772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unarchive pigz</th>\n",
       "      <td>0.933855</td>\n",
       "      <td>1.131042e+07</td>\n",
       "      <td>86.947520</td>\n",
       "      <td>12339.482427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>648.862088</td>\n",
       "      <td>11706.481413</td>\n",
       "      <td>43.690047</td>\n",
       "      <td>108.359969</td>\n",
       "      <td>154.140794</td>\n",
       "      <td>43.473760</td>\n",
       "      <td>22659.633941</td>\n",
       "      <td>47791.071958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write</th>\n",
       "      <td>0.999957</td>\n",
       "      <td>1.131861e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.239273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.866270</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.179142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.985698</td>\n",
       "      <td>8.449525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cputime_per_sec   memory_mean  socket_syscalls_per_sec  \\\n",
       "workload                                                                   \n",
       "a-data-sci               1.846697  5.019648e+08                 1.505072   \n",
       "archive                  0.641795  8.645291e+06               299.254091   \n",
       "archive bzip2            1.012189  9.310208e+06                18.078526   \n",
       "archive gzip             1.026436  3.751936e+06                85.001375   \n",
       "archive pbzip2           5.782112  5.392111e+07                53.239038   \n",
       "...                           ...           ...                      ...   \n",
       "unarchive bzip2          1.085411  1.425408e+07                26.959380   \n",
       "unarchive gzip           1.000682  1.138278e+07               116.492802   \n",
       "unarchive pbzip2         3.238676  4.018859e+07                52.587740   \n",
       "unarchive pigz           0.933855  1.131042e+07                86.947520   \n",
       "write                    0.999957  1.131861e+06                 0.000000   \n",
       "\n",
       "                  metadata_syscalls_per_sec  chmod_syscalls_per_sec  \\\n",
       "workload                                                              \n",
       "a-data-sci                      1822.089894                0.082848   \n",
       "archive                       122776.062947                0.000000   \n",
       "archive bzip2                   3815.702057                0.000000   \n",
       "archive gzip                   14739.397643                0.000000   \n",
       "archive pbzip2                 10807.663452                0.000000   \n",
       "...                                     ...                     ...   \n",
       "unarchive bzip2                 3829.953241                0.000000   \n",
       "unarchive gzip                 11320.507291                0.000000   \n",
       "unarchive pbzip2                6911.684236                0.000000   \n",
       "unarchive pigz                 12339.482427                0.000000   \n",
       "write                              2.239273                0.000000   \n",
       "\n",
       "                  dir_syscalls_per_sec  file_syscalls_per_sec  \\\n",
       "workload                                                        \n",
       "a-data-sci                    1.491264             722.116985   \n",
       "archive                       0.000000           41635.028198   \n",
       "archive bzip2                 0.000000            1370.741457   \n",
       "archive gzip                  0.000000            5254.341122   \n",
       "archive pbzip2                0.000000            3970.368904   \n",
       "...                                ...                    ...   \n",
       "unarchive bzip2             201.189403            3604.576401   \n",
       "unarchive gzip              580.528912           10481.126988   \n",
       "unarchive pbzip2            356.709607            6608.789943   \n",
       "unarchive pigz              648.862088           11706.481413   \n",
       "write                         0.000000               2.866270   \n",
       "\n",
       "                  exec_syscalls_per_sec  clone_syscalls_per_sec  \\\n",
       "workload                                                          \n",
       "a-data-sci                     4.473792                1.242720   \n",
       "archive                       75.930143               75.185729   \n",
       "archive bzip2                  8.965373                4.507317   \n",
       "archive gzip                  40.895011               17.165106   \n",
       "archive pbzip2                25.335396               81.420327   \n",
       "...                                 ...                     ...   \n",
       "unarchive bzip2               13.569107               13.479690   \n",
       "unarchive gzip                58.439910               38.895437   \n",
       "unarchive pbzip2              23.997116              154.555684   \n",
       "unarchive pigz                43.690047              108.359969   \n",
       "write                          0.089571                0.089571   \n",
       "\n",
       "                  exits_syscalls_per_sec  dups_syscalls_per_sec  \\\n",
       "workload                                                          \n",
       "a-data-sci                      1.132256               1.118448   \n",
       "archive                        76.178280               0.744413   \n",
       "archive bzip2                   4.605837               7.241263   \n",
       "archive gzip                   17.278782              36.149030   \n",
       "archive pbzip2                 84.890930              19.851845   \n",
       "...                                  ...                    ...   \n",
       "unarchive bzip2                13.703234              13.502044   \n",
       "unarchive gzip                 39.475966              58.246401   \n",
       "unarchive pbzip2              198.471198              23.917918   \n",
       "unarchive pigz                154.140794              43.473760   \n",
       "write                           0.179142               0.000000   \n",
       "\n",
       "                  other_syscalls_per_sec  n_ops_per_sec  \n",
       "workload                                                 \n",
       "a-data-sci                    474.014838    3029.268116  \n",
       "archive                     40435.778592  205374.162394  \n",
       "archive bzip2                1267.073177    6496.915007  \n",
       "archive gzip                 4924.566478   25114.794549  \n",
       "archive pbzip2               3614.632180   18657.402070  \n",
       "...                                  ...            ...  \n",
       "unarchive bzip2              7011.249493   14728.181994  \n",
       "unarchive gzip              20418.685404   43112.399111  \n",
       "unarchive pbzip2            12540.948330   26871.661772  \n",
       "unarchive pigz              22659.633941   47791.071958  \n",
       "write                           2.985698       8.449525  \n",
       "\n",
       "[250 rows x 13 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noprov = agged.loc[\"noprov\"]\n",
    "strace = agged.loc[\"strace\"]\n",
    "features_df = pandas.DataFrame({\n",
    "    \"cputime_per_sec\": noprov[\"cputime_mean\"] / noprov[\"walltime_mean\"],\n",
    "    \"memory_mean\": noprov[\"memory_mean\"],\n",
    "    **{\n",
    "        group_name + \"_syscalls_per_sec\": strace[\"op_type_counts_sum\"].map(lambda op_type_counts: sum(\n",
    "            op_type_counts[syscall_name]\n",
    "            for syscall_name in syscall_names\n",
    "        )) / (noprov[\"walltime_mean\"] * noprov[\"count\"])\n",
    "        for group_name, syscall_names in syscall_groups.items()\n",
    "    },\n",
    "    \"n_ops_per_sec\": strace[\"n_ops_mean\"] / noprov[\"walltime_mean\"],\n",
    "})\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e5ae0-8dfa-40d7-b2d2-f495581fe69e",
   "metadata": {},
   "source": [
    "## Actually creating Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "0d90d9af-f4eb-44f0-b43b-bbbf2df06e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = agged.reset_index().pivot(index=\"collector\", columns=\"workload\", values=\"log_rel_slowdown\")\n",
    "noprov_index = list(agged.index.levels[0]).index(\"noprov\")\n",
    "strace_index = list(agged.index.levels[0]).index(\"strace\")\n",
    "\n",
    "assert all(\n",
    "    workload0 == workload1\n",
    "    for workload0, workload1 in zip(tmp_df.columns, features_df.index)\n",
    ")\n",
    "\n",
    "systems_by_benchmarks = tmp_df.values\n",
    "benchmarks_by_features = features_df.values\n",
    "\n",
    "\n",
    "collector_names = agged.index.levels[0]\n",
    "benchmark_names = agged.index.levels[1]\n",
    "feature_names = features_df.columns\n",
    "\n",
    "\n",
    "n_systems, n_benchmarks = systems_by_benchmarks.shape\n",
    "_, n_features = benchmarks_by_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830818c-ddb4-4fde-a2e9-2b8ecdfa41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_by_benchmarks = numpy.load(\"output/systems_by_benchmarks.npy\")\n",
    "benchmarks_by_features = numpy.load(\"output/benchmarks_by_features.npy\")\n",
    "collector_names = pathlib.Path(\"output/collectors.txt\").read_text().split(\"\\n\")\n",
    "benchmark_names = pathlib.Path(\"output/benchmark_names.txt\").read_text().split(\"\\n\")\n",
    "feature_names = pathlib.Path(\"output/feature_names.txt\").read_text().split(\"\\n\")\n",
    "\n",
    "\n",
    "n_systems, n_benchmarks = systems_by_benchmarks.shape\n",
    "_, n_features = benchmarks_by_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04587d59-13f1-42b9-9286-9dcc7bcf9c97",
   "metadata": {},
   "source": [
    "# Let's play the new system game\n",
    "\n",
    "It is more of a dialogue.\n",
    "\n",
    "- **Given** integer N and workloads x benchmark matrix\n",
    "- **Select** N workloads\n",
    "- **Given** new system's log slowdown ratio on N selected workloads\n",
    "- **Predict** new system's log slowdown ratio on all other workloads\n",
    "\n",
    "I initially scored this game by cross-validated root-mean-squared-error. However, I've found that even with cross-validation, more complex models are not \"punished\" enough. So I decided to also include Akaike Information Criterion (modified for small sample size). But in order to compute the AIC, one has to know the likelihood function. If you're lazy, your model has uninformitave priors, and your errors are normally distributed (although with unknown variance), you can use `naive_log_likelihood`, which computes the likelihood-maximizing variance, and returns the likelihood of the data based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "57cea0e6-a979-42f4-b331-6c33f26c42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewSystemPredictor:\n",
    "    @abc.abstractmethod\n",
    "    def select_benchmarks(\n",
    "        self,\n",
    "        k: int,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[list[int], numpy.float64]:\n",
    "        \"\"\"\n",
    "        k: number of benchmarks to select\n",
    "        systems_by_benchmarks: array where the (i,j)th element is the log of the ith system's slowdown on the jth benchmark\n",
    "        benchmarks_by_features: array where the (j,m)th element is the mth feature of the jth benchmark\n",
    "\n",
    "        returns a tuple containing:\n",
    "          - k benchmarks to select\n",
    "          - the log-liklihood\n",
    "        \n",
    "        Liklihood is the probability of observing this data given the parameters you inferred\n",
    "        Used to compute the Akaike Information Criterion.\n",
    "        Return numpy.NaN if you just don't care.\n",
    "        \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict_new_system(\n",
    "        new_systems_by_selected_benchmarks: numpy.typing.NDArray,\n",
    "    ) -> numpy.typing.NDArray:\n",
    "        \"\"\"\n",
    "        new_system_by_selected_benchmarks: array where the (g,p)th element is the log of the gth new system's slowdown on the pth *selected* benchmark\n",
    "\n",
    "        returns an array where the (g,q)th element is the log of the gth new system's slowdown on the qth *unselected* benchmark\n",
    "        \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def n_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of parameters used to make this estimation.\n",
    "        Used to calculate the Akaike Information Criterion.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "0643da70-9b09-4ec4-bf8b-d1f0c69416a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "mean_absolute_error = lambda a, b: numpy.mean(numpy.fabs(a - b))\n",
    "\n",
    "root_mean_squared_error = lambda a, b: numpy.sqrt(numpy.mean((a-b)**2))\n",
    "\n",
    "\n",
    "def aicc(k: int, log_likelihood: float, n_points: int) -> float:\n",
    "    aic = 2 * k - 2 * log_likelihood\n",
    "    return aic + (2 * k**2 + 2 * k) / (n_points - k - 1)\n",
    "\n",
    "\n",
    "def test_system_predictors(\n",
    "    predictors: list[NewSystemPredictor]\n",
    ") -> None:\n",
    "    systems = list(range(n_systems))\n",
    "    cv_splitter = sklearn.model_selection.LeaveOneOut()\n",
    "    print(\"RMSE (lower is better), stddev RMSE (lower is better), AICc (higher is better)\")\n",
    "    for predictor in predictors:\n",
    "        results = []\n",
    "        selected = collections.Counter()\n",
    "        for train_systems, test_systems in cv_splitter.split(systems):\n",
    "            selected_benchmarks, _ = predictor.select_benchmarks(\n",
    "                systems_by_benchmarks[train_systems],\n",
    "                benchmarks_by_features,\n",
    "            )\n",
    "            unselected_benchmarks = [\n",
    "                benchmark\n",
    "                for benchmark in range(n_benchmarks)\n",
    "                if benchmark not in selected_benchmarks\n",
    "            ]\n",
    "            predicted = predictor.predict_new_systems(\n",
    "                systems_by_benchmarks[test_systems, :][:, selected_benchmarks],\n",
    "            )\n",
    "            for benchmark in selected_benchmarks:\n",
    "                selected[benchmark] += 1\n",
    "            actual = systems_by_benchmarks[test_systems, :][:, unselected_benchmarks]\n",
    "            results.append(root_mean_squared_error(actual, predicted))\n",
    "        result_mean = numpy.mean(results)\n",
    "        result_std = numpy.std(results)\n",
    "        _, log_likelihood = predictor.select_benchmarks(systems_by_benchmarks, benchmarks_by_features)\n",
    "        n_datapoints = len(systems_by_benchmarks.flatten()) + len(benchmarks_by_features.flatten())\n",
    "        my_aicc = aicc(predictor.n_parameters(), log_likelihood, n_datapoints)\n",
    "        print(\n",
    "            f\"{result_mean:.2f}\",\n",
    "            f\"{result_std:.2f}\",\n",
    "            f\"{numpy.log(my_aicc):.2f}\",\n",
    "            predictor,\n",
    "            {benchmark_names[benchmark]: count for benchmark, count in selected.items()},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed55e2d-55b9-41c4-96a1-c20609551623",
   "metadata": {},
   "source": [
    "Assume a model predicts $\\hat{r}_i = f(r_i) + \\eta_i$ where $\\eta_i$ is normally distributed around 0 with unknown variance.\n",
    "\n",
    "Let's find the variance which maximizes likelihood.\n",
    "\n",
    "First, I'll write down the PDF (which is likelihood function) for the Normal distribution, where $\\mu$ is the prediction and $x$ is the observation:\n",
    "\n",
    "$$f(x | \\mu, \\sigma) = \\frac{1}{\\sigma * \\sqrt{2\\pi}) * \\exp(-\\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right^2 $$\n",
    "\n",
    "Then log both sides.\n",
    "\n",
    "$$\\log f(x | \\mu, \\sigma) = -\\log(\\sigma \\sqrt{2\\pi}) - \\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right)^2 $$\n",
    "\n",
    "In order to maximize, take a derivative with $\\sigma$.\n",
    "\n",
    "$$\\frac{d}{d\\sigma} \\log f(x | \\mu, \\sigma) = -\\frac{1}{\\sigma} + \\frac{(x - \\mu)^2}{\\sigma^3} $$\n",
    "\n",
    "Set that to zero.\n",
    "\n",
    "$$0 = \\frac{d}{d\\sigma} \\log f(x | \\mu, \\sigma) \\implies \\frac{1}{\\sigma} = \\frac{(x - \\mu)^2}{\\sigma^3} \\implies \\sigma = |x - \\mu|$$\n",
    "\n",
    "Therefore $\\log f(x | \\mu, \\sigma)$ has a maximum at $\\sigma = x - \\mu|$.\n",
    "\n",
    "We can plug that back in to the log-likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "b55277eb-a8ff-4a74-8e8e-c665adf29761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_log_likelihood(actual, predicted) -> float:\n",
    "    std = numpy.clip(actual - predicted, 1e-2, None)\n",
    "    # Some of the values we hit \"dead-on\"\n",
    "    # This predicts the sigma should be 0, which is wrong\n",
    "    # It should actually be a small positive number.\n",
    "    \n",
    "    # Plugging this in to the log PDF above\n",
    "    return numpy.sum(-1/2*((actual - predicted)/std)**2 - numpy.log(std) + 1/2*numpy.log(2*numpy.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "6d1bcbf9-0b2d-412e-843c-c0318be9738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg.interpolative\n",
    "\n",
    "class InitialSystemPredictor(NewSystemPredictor):\n",
    "    \"\"\"\n",
    "    This is a simple predictor just to test the mechanics.\n",
    "\n",
    "    It simply selects self.benchmarks.\n",
    "    Then it runs a regression to all the unselected benchmarks based on the selected benchmarks.\n",
    "    That's it.\n",
    "    \"\"\"\n",
    "    def __init__(self, benchmarks: list[int]) -> None:\n",
    "        self.benchmarks = benchmarks\n",
    "\n",
    "    def select_benchmarks(\n",
    "        self,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[list[int], numpy.float64]:\n",
    "        unselected_benchmarks = [\n",
    "            benchmark\n",
    "            for benchmark in range(systems_by_benchmarks.shape[1])\n",
    "            if benchmark not in self.benchmarks\n",
    "        ]\n",
    "        self.coeffs = numpy.linalg.pinv(systems_by_benchmarks[:, self.benchmarks]) @ systems_by_benchmarks[:, unselected_benchmarks]\n",
    "        log_likelihood = naive_log_likelihood(\n",
    "            systems_by_benchmarks[:, unselected_benchmarks],\n",
    "            systems_by_benchmarks[:, self.benchmarks] @ self.coeffs,\n",
    "        )\n",
    "        # the selected benchmarks will get probability = 1, log likelihood = 0, so you can imagine I wrote ... + 0 + 0 + 0 to the end\n",
    "        return self.benchmarks, log_likelihood\n",
    "\n",
    "    def predict_new_systems(\n",
    "        self,\n",
    "        new_systems_by_selected_benchmarks: numpy.typing.NDArray,\n",
    "    ) -> numpy.typing.NDArray:\n",
    "        return new_systems_by_selected_benchmarks @ self.coeffs\n",
    "\n",
    "    def n_parameters(self) -> int:\n",
    "        return len(self.coeffs)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.benchmarks!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "85780d36-b787-4fbe-8a49-f0bf7cf02659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg.interpolative\n",
    "\n",
    "class InterpolativeDecompositionSystemPredictor(NewSystemPredictor):\n",
    "    \"\"\"\n",
    "    This method uses Interpolative Decomposition (ID).\n",
    "\n",
    "    ID factors a matrix A into B @ C.\n",
    "    It selects k columns of A, and puts those in B.\n",
    "    It puts the identity matrix in the corresponding columns of C.\n",
    "    The remaining N - k columns of A are predicted from a linear regression on the k columns of A (equivalently, all the columns of B).\n",
    "\n",
    "    This method should be pretty good.\n",
    "    \"\"\"\n",
    "    def __init__(self, k: int, use_features: bool) -> None:\n",
    "        self.k = k\n",
    "        self.use_features = use_features\n",
    "\n",
    "    def select_benchmarks(\n",
    "        self,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[list[int], numpy.float64]:\n",
    "        if self.use_features:\n",
    "            data = numpy.vstack([\n",
    "                systems_by_benchmarks,\n",
    "                benchmarks_by_features.T,\n",
    "            ])\n",
    "        else:\n",
    "            data = systems_by_benchmarks\n",
    "        idx, proj = scipy.linalg.interpolative.interp_decomp(data, self.k, rand=False)\n",
    "        self.idx = idx\n",
    "        self.proj = proj\n",
    "        # skel = scipy.linalg.interpolative.reconstruct_skel_matrix(data, self.k, idx)\n",
    "        # data_est = scipy.linalg.interpolative.reconstruct_matrix_from_id(skel, idx, proj)[:len(systems_by_benchmarks), :]\n",
    "        log_likelihood = naive_log_likelihood(\n",
    "            systems_by_benchmarks[:, self.idx[self.k:]],\n",
    "            systems_by_benchmarks[:, self.idx[:self.k]] @ self.proj,\n",
    "        )\n",
    "        return idx[:self.k], log_likelihood\n",
    "\n",
    "    def predict_new_systems(\n",
    "        self,\n",
    "        new_systems_by_selected_benchmarks: numpy.typing.NDArray,\n",
    "    ) -> numpy.typing.NDArray:\n",
    "        return new_systems_by_selected_benchmarks @ self.proj\n",
    "\n",
    "    def n_parameters(self) -> int:\n",
    "        return len(self.proj.flatten())\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.k}, {self.use_features})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "56015461-8d5a-4805-b185-3657f18a4929",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.pca = sklearn.decomposition.PCA(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg.interpolative\n",
    "\n",
    "class ClusteringSystemPredictor(NewSystemPredictor):\n",
    "    def __init__(self, k: int, use_features: bool, whiten: bool) -> None:\n",
    "        self.k = k\n",
    "        self.use_features = use_features\n",
    "        self.whiten = whiten\n",
    "\n",
    "    def select_benchmarks(\n",
    "        self,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[list[int], numpy.float64]:\n",
    "        if self.use_features:\n",
    "            data = numpy.vstack([\n",
    "                systems_by_benchmarks,\n",
    "                benchmarks_by_features.T,\n",
    "            ])\n",
    "        else:\n",
    "            data = systems_by_benchmarks\n",
    "        self.pca = sklearn.decomposition.PCA(\n",
    "            n_components=self.k,\n",
    "            whiten=self.whiten,\n",
    "            random_state=0,\n",
    "        )\n",
    "        self.rotated_data = self.pca.fit_transform(data)\n",
    "        self.kmeans = sklearn.cluster.KMeans(n_clusters=self.k, random_state=0)\n",
    "        self.kmeans.fit(small_data)\n",
    "        self.selected_benchmarks = [\n",
    "            min(\n",
    "                self.rotated_data.T,\n",
    "                key=lambda benchmark: scipy.spatial.distance.euclidean(benchmark, cluster_center),\n",
    "            )\n",
    "            for cluster_center in self.kmeans.cluster_centers_\n",
    "        ]\n",
    "        unselected_benchmarks = [\n",
    "            benchmark\n",
    "            for benchmark in range(systems_by_benchmarks.shape[1])\n",
    "            if benchmark not in self.selected_benchmarks\n",
    "        ]\n",
    "        log_likelihood = naive_log_likelihood(\n",
    "            systems_by_benchmarks[:, unselected_benchmarks],\n",
    "            systems_by_benchmarks[:, selected_benchmarks],\n",
    "        )\n",
    "        return idx[:self.k], log_likelihood\n",
    "\n",
    "    def plot(self, ax: \"maptloltib.axes.Axes\") -> None:\n",
    "        import matplotlib.cm\n",
    "        colors = sorted(matplotlib.cm.Dark2.colors + matplotlib.cm.Set2.colors)\n",
    "        for i in range(len(self.rotated_data)):\n",
    "            ax.plot(\n",
    "                self.rotated_data[i, 0],\n",
    "                self.rotated_data[i, 1], \n",
    "                color=colors[self.kmeans.labels_[i]],\n",
    "                marker=\"o\",\n",
    "            )\n",
    "\n",
    "    def predict_new_systems(\n",
    "        self,\n",
    "        new_systems_by_selected_benchmarks: numpy.typing.NDArray,\n",
    "    ) -> numpy.typing.NDArray:\n",
    "        return new_systems_by_selected_benchmarks @ self.proj\n",
    "\n",
    "    def n_parameters(self) -> int:\n",
    "        return len(self.proj.flatten())\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.k}, {self.use_features})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "48ed3509-1d72-4f85-9a4b-e6bc17eb35d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Disable line wrapping in cell outputs to make the output more readable -->\n",
       "<style>\n",
       "div.jp-OutputArea-output pre {\n",
       "    white-space: pre;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- Disable line wrapping in cell outputs to make the output more readable -->\n",
    "<style>\n",
    "div.jp-OutputArea-output pre {\n",
    "    white-space: pre;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "f3b3001f-0443-4235-b275-3832d24fc1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 1.21 11.62 InitialSystemPredictor([0]) {'a-data-sci': 5}\n",
      "1.12 0.90 14.09 InitialSystemPredictor([0, 1]) {'a-data-sci': 5, 'archive': 5}\n",
      "1.26 1.06 11.68 InitialSystemPredictor([10, 20, 30]) {'blastn-NM_003949': 5, 'blastn-NM_024506': 5, 'blastn-NM_068205': 5}\n",
      "0.56 0.51 11.97 InterpolativeDecompositionSystemPredictor(1, True) {'megablast-NG_008953': 5}\n",
      "0.53 0.50 11.71 InterpolativeDecompositionSystemPredictor(2, True) {'megablast-NG_008953': 5, 'postmark': 5}\n",
      "0.52 0.50 11.65 InterpolativeDecompositionSystemPredictor(3, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5}\n",
      "0.53 0.50 11.81 InterpolativeDecompositionSystemPredictor(4, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5}\n",
      "0.53 0.51 11.71 InterpolativeDecompositionSystemPredictor(5, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5}\n",
      "0.54 0.51 11.70 InterpolativeDecompositionSystemPredictor(6, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5}\n",
      "0.54 0.50 11.71 InterpolativeDecompositionSystemPredictor(7, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5}\n",
      "0.54 0.51 11.68 InterpolativeDecompositionSystemPredictor(8, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5}\n",
      "0.54 0.50 11.70 InterpolativeDecompositionSystemPredictor(9, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5}\n",
      "0.52 0.50 11.84 InterpolativeDecompositionSystemPredictor(10, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5}\n",
      "0.54 0.51 11.64 InterpolativeDecompositionSystemPredictor(11, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5, 'proftpd with ftpbench': 5}\n",
      "0.51 0.46 11.86 InterpolativeDecompositionSystemPredictor(12, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5, 'proftpd with ftpbench': 5, 'archive pbzip2': 5}\n",
      "0.53 0.45 13.25 InterpolativeDecompositionSystemPredictor(13, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5, 'proftpd with ftpbench': 5, 'archive pbzip2': 5, 'hg schema-validation': 4, 'stat': 1}\n",
      "0.53 0.42 13.12 InterpolativeDecompositionSystemPredictor(14, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5, 'proftpd with ftpbench': 5, 'archive pbzip2': 5, 'hg schema-validation': 4, 'stat': 4, 'open/close': 2}\n",
      "0.48 0.40 11.56 InterpolativeDecompositionSystemPredictor(15, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5, 'proftpd with ftpbench': 5, 'archive pbzip2': 5, 'hg schema-validation': 4, 'stat': 4, 'blastn-XM_546594': 2, 'fs': 1, 'open/close': 3, 'page-fault': 1}\n",
      "0.44 0.37 10.36 InterpolativeDecompositionSystemPredictor(16, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5, 'proftpd with ftpbench': 5, 'archive pbzip2': 5, 'hg schema-validation': 4, 'stat': 4, 'blastn-XM_546594': 2, 'megablast-NG_000006': 1, 'fs': 1, 'blastn-NM_123974': 1, 'open/close': 3, 'fstat': 1, 'page-fault': 1, 'archive pigz': 1, 'blastn-NM_181804': 1}\n",
      "0.40 0.30 10.89 InterpolativeDecompositionSystemPredictor(17, True) {'megablast-NG_008953': 5, 'postmark': 5, 'archive': 5, 'gcc-hello-world': 5, 'true': 5, 'fork': 5, 'exec': 5, 'git setuptools_scm': 5, 'python-hello-world': 5, 'unarchive pigz': 5, 'proftpd with ftpbench': 5, 'archive pbzip2': 5, 'hg schema-validation': 4, 'stat': 4, 'blastn-XM_546594': 2, 'megablast-NG_000006': 1, 'hello': 1, 'fs': 3, 'blastn-NM_123974': 1, 'a-data-sci': 2, 'open/close': 3, 'fstat': 1, 'page-fault': 1, 'archive pigz': 1, 'blastn-NM_181804': 1}\n",
      "0.52 0.43 12.99 InterpolativeDecompositionSystemPredictor(1, False) {'echo': 3, 'postmark': 2}\n",
      "0.52 0.42 13.34 InterpolativeDecompositionSystemPredictor(2, False) {'echo': 4, 'stat': 1, 'postmark': 3, 'open/close': 2}\n",
      "0.69 0.47 10.66 InterpolativeDecompositionSystemPredictor(3, False) {'echo': 4, 'stat': 3, 'postmark': 4, 'fs': 2, 'open/close': 2}\n",
      "0.64 0.45 nan InterpolativeDecompositionSystemPredictor(4, False) {'echo': 4, 'stat': 4, 'postmark': 4, 'blastn-NM_125747': 1, 'fs': 2, 'blastn-NM_105054': 1, 'open/close': 2, 'mmap': 1, 'page-fault': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_297091/1093098599.py:47: RuntimeWarning: invalid value encountered in log\n",
      "  f\"{numpy.log(my_aicc):.2f}\",\n"
     ]
    }
   ],
   "source": [
    "test_system_predictors([\n",
    "    InitialSystemPredictor([0]),\n",
    "    InitialSystemPredictor([0, 1]),\n",
    "    InitialSystemPredictor([10, 20, 30]),\n",
    "    *[\n",
    "        InterpolativeDecompositionSystemPredictor(k, True)\n",
    "        for k in range(1, n_systems + n_features)\n",
    "    ],\n",
    "    *[\n",
    "        InterpolativeDecompositionSystemPredictor(k, False)\n",
    "        for k in range(1, n_systems)\n",
    "    ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "0591b279-1639-4cb9-ac9a-f4654f7b261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_benchmark_predictors(\n",
    "    predictors: list[NewBenchmarkPredictor],\n",
    ") -> None:\n",
    "    benchmarks = list(range(n_benchmarks))\n",
    "    test_size = 0.1\n",
    "    cv_splitter = sklearn.model_selection.ShuffleSplit(n_splits=10, test_size=test_size, random_state=0)\n",
    "    for predictor in predictors:\n",
    "        results = []\n",
    "        for train_benchmarks, test_benchmarks in cv_splitter.split(benchmarks):\n",
    "            predicted, _ = predictor.predict_new_benchmark(\n",
    "                systems_by_benchmarks[:, train_benchmarks],\n",
    "                benchmarks_by_features[train_benchmarks, :],\n",
    "                benchmarks_by_features[test_benchmarks, :],\n",
    "            )\n",
    "            actual = systems_by_benchmarks[:, test_benchmarks]\n",
    "            results.append(root_mean_squared_error(actual, predicted))\n",
    "        result_mean = numpy.mean(results)\n",
    "        result_std = numpy.std(results)\n",
    "        _, log_likelihood = predictor.predict_new_benchmark(systems_by_benchmarks, benchmarks_by_features, benchmarks_by_features)\n",
    "        n_datapoints = len(systems_by_benchmarks.flatten()) + len(benchmarks_by_features.flatten())\n",
    "        my_aicc = aicc(predictor.n_parameters(), log_likelihood, n_datapoints)\n",
    "        print(\n",
    "            f\"{result_mean:.2f}\",\n",
    "            f\"{result_std:.2f}\",\n",
    "            f\"{numpy.log(my_aicc):.2f}\",\n",
    "            predictor,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "bba004ae-063f-4347-99f9-eac7902bcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg.interpolative\n",
    "\n",
    "class Regression(NewBenchmarkPredictor):\n",
    "    \"\"\"\n",
    "    This method simply regresses performance on the full set of featuers.\n",
    "\n",
    "    No linear method should be able to do better in RMSE, but dimensionality reduction may help with AIC.\n",
    "    \"\"\"\n",
    "    def n_parameters(self) -> int:\n",
    "        return len(self.systems_by_features.flatten())\n",
    "\n",
    "    def predict_new_benchmark(\n",
    "        self,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "        new_benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[numpy.typing.NDArray, numpy.float64]:\n",
    "        self.systems_by_features = systems_by_benchmarks @ numpy.linalg.pinv(benchmarks_by_features.T)\n",
    "        log_likelihood = naive_log_likelihood(\n",
    "            self.systems_by_features @ benchmarks_by_features.T,\n",
    "            systems_by_benchmarks,\n",
    "        )\n",
    "        return self.systems_by_features @ new_benchmarks_by_features.T, log_likelihood\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "bdafebb4-4532-4dfb-9ced-802c5b682cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg.interpolative\n",
    "\n",
    "class LowRankMatrixFactorization(NewBenchmarkPredictor):\n",
    "    \"\"\"\n",
    "    Like Regression, but use a low-rank compression\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "\n",
    "    def n_parameters(self) -> int:\n",
    "        return len(self.a.flatten()) + len(self.b.flatten())\n",
    "\n",
    "    def predict_new_benchmark(\n",
    "        self,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "        new_benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[numpy.typing.NDArray, numpy.float64]:\n",
    "        tmp = systems_by_benchmarks @ numpy.linalg.pinv(benchmarks_by_features.T)\n",
    "        u, s, vh = numpy.linalg.svd(tmp, full_matrices=False)\n",
    "        self.a = (u[:, :self.dim] * s[:self.dim])\n",
    "        self.b = vh[:self.dim, :]\n",
    "        log_likelihood = naive_log_likelihood(\n",
    "            self.a @ self.b @ benchmarks_by_features.T,\n",
    "            systems_by_benchmarks,\n",
    "        )\n",
    "        return self.a @ self.b @ new_benchmarks_by_features.T, log_likelihood\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.dim})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "e8984333-7fc2-47a7-88f4-69bb3ae3d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg.interpolative\n",
    "\n",
    "class GreedySubsetMatrixFactorization(NewBenchmarkPredictor):\n",
    "    \"\"\"\n",
    "    This method tries to select only dim features.\n",
    "\n",
    "    This is subtly different from \"compressing to a matrix of rank dim\".\n",
    "\n",
    "    Using only dim features, means the other coefficients **have to be** zero.\n",
    "\n",
    "    It's greedy because it picks the best feature, and adds next best given the current set, etc.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "\n",
    "    def n_parameters(self) -> int:\n",
    "        return len(self.systems_by_features.flatten())\n",
    "\n",
    "    def predict_new_benchmark(\n",
    "        self,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "        new_benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[numpy.typing.NDArray, numpy.float64]:\n",
    "        def test_goodness(features: list[int]) -> numpy.float64:\n",
    "            systems_by_features = systems_by_benchmarks @ numpy.linalg.pinv(benchmarks_by_features[:, features].T)\n",
    "            return numpy.sum((systems_by_features @ benchmarks_by_features[:, features].T - systems_by_benchmarks)**2)\n",
    "        selected_features = []\n",
    "        while len(selected_features) < self.dim:\n",
    "            unselected_features = [\n",
    "                feature\n",
    "                for feature in range(benchmarks_by_features.shape[1])\n",
    "                if feature not in selected_features\n",
    "            ]\n",
    "            selected_features = max([\n",
    "                selected_features + [candidate_feature]\n",
    "                for candidate_feature in unselected_features\n",
    "            ], key=test_goodness)\n",
    "        self.features = selected_features\n",
    "        self.systems_by_features = systems_by_benchmarks @ numpy.linalg.pinv(benchmarks_by_features[:, self.features].T)\n",
    "        log_likelihood = naive_log_likelihood(\n",
    "            self.systems_by_features @ benchmarks_by_features[:, self.features].T,\n",
    "            systems_by_benchmarks\n",
    "        )\n",
    "        return self.systems_by_features @ new_benchmarks_by_features[:, self.features].T, log_likelihood\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        features = \", \".join(feature_names[i] for i in self.features)\n",
    "        return f\"{self.__class__.__name__}({self.dim}): {features}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "e6a67dd4-9432-477e-919a-ed197d07814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59 0.33 13.99 MatrixFactorization()\n",
      "0.60 0.31 14.25 LowRankMatrixFactorization(1)\n",
      "0.59 0.31 14.01 LowRankMatrixFactorization(2)\n",
      "0.59 0.33 14.04 LowRankMatrixFactorization(3)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(4)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(5)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(6)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(7)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(8)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(9)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(10)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(11)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(12)\n",
      "0.59 0.33 13.99 LowRankMatrixFactorization(13)\n",
      "0.74 0.09 15.73 GreedySubsetMatrixFactorization(1): chmod_syscalls_per_sec\n",
      "0.73 0.08 15.69 GreedySubsetMatrixFactorization(2): chmod_syscalls_per_sec, memory_mean\n",
      "0.71 0.07 15.64 GreedySubsetMatrixFactorization(3): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec\n",
      "0.71 0.07 15.63 GreedySubsetMatrixFactorization(4): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec\n",
      "0.71 0.07 15.61 GreedySubsetMatrixFactorization(5): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec\n",
      "0.71 0.06 15.59 GreedySubsetMatrixFactorization(6): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec\n",
      "0.70 0.08 15.53 GreedySubsetMatrixFactorization(7): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec, dups_syscalls_per_sec\n",
      "0.69 0.08 15.48 GreedySubsetMatrixFactorization(8): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec, dups_syscalls_per_sec, metadata_syscalls_per_sec\n",
      "0.73 0.21 15.47 GreedySubsetMatrixFactorization(9): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec, dups_syscalls_per_sec, metadata_syscalls_per_sec, other_syscalls_per_sec\n",
      "0.75 0.25 15.47 GreedySubsetMatrixFactorization(10): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec, dups_syscalls_per_sec, metadata_syscalls_per_sec, other_syscalls_per_sec, file_syscalls_per_sec\n",
      "0.75 0.28 15.43 GreedySubsetMatrixFactorization(11): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec, dups_syscalls_per_sec, metadata_syscalls_per_sec, other_syscalls_per_sec, file_syscalls_per_sec, socket_syscalls_per_sec\n",
      "0.75 0.28 15.43 GreedySubsetMatrixFactorization(12): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec, dups_syscalls_per_sec, metadata_syscalls_per_sec, other_syscalls_per_sec, file_syscalls_per_sec, socket_syscalls_per_sec, n_ops_per_sec\n",
      "0.59 0.33 13.99 GreedySubsetMatrixFactorization(13): chmod_syscalls_per_sec, memory_mean, clone_syscalls_per_sec, exits_syscalls_per_sec, exec_syscalls_per_sec, dir_syscalls_per_sec, dups_syscalls_per_sec, metadata_syscalls_per_sec, other_syscalls_per_sec, file_syscalls_per_sec, socket_syscalls_per_sec, n_ops_per_sec, cputime_per_sec\n"
     ]
    }
   ],
   "source": [
    "test_benchmark_predictors([\n",
    "    Regression(),\n",
    "    *[\n",
    "        LowRankMatrixFactorization(i)\n",
    "        for i in range(1, n_features + 1)\n",
    "    ],\n",
    "    *[\n",
    "        GreedySubsetMatrixFactorization(i)\n",
    "        for i in range(1, n_features + 1)\n",
    "    ],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36ca56-dd17-4058-b5f5-4b327d334c53",
   "metadata": {},
   "source": [
    "# What about new-system-and-benchmark?\n",
    "\n",
    "- **Given** integer N and workloads x benchmark matrix\n",
    "- **Select** N workloads\n",
    "- **Given** new system's log slowdown ratio on N selected workloads and features of new workload\n",
    "- **Predict** new system's log slowdown ratio on new workload\n",
    "\n",
    "Not implemented yet. Maybe won't be ever. Who would be picking a new system and new benchmark at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9337c1-cb11-43d4-9a81-b162e49f7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore this clase\n",
    "\n",
    "class NewSystemAndBenchmarkProblem(abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def select_benchmarks(\n",
    "        self,\n",
    "        k: int,\n",
    "        systems_by_benchmarks: numpy.typing.NDArray,\n",
    "        benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> tuple[list[int], numpy.float64]:\n",
    "        \"\"\"\n",
    "        k: number of benchmarks to select\n",
    "        systems_by_benchmarks: array where the (i,j)th element is the log of the ith system's slowdown on the jth benchmark\n",
    "        benchmarks_by_features: array where the (j,m)th element is the mth feature of the jth benchmark\n",
    "\n",
    "\n",
    "        returns a tuple containing:\n",
    "          - k benchmarks to select\n",
    "          - the log-liklihood\n",
    "        \n",
    "        Liklihood is the probability of observing this data given the parameters you inferred\n",
    "        Used to compute the Akaike Information Criterion.\n",
    "        Return numpy.NaN if you just don't care.     \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def n_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of parameters used to make this estimation.\n",
    "        Used to calculate the Akaike Information Criterion.\n",
    "        \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict_new_system_on_new_benchmarks(\n",
    "        self,\n",
    "        new_system_by_selected_benchmarks: numpy.typing.NDArray,\n",
    "        selected_benchmarks_by_features: numpy.typing.NDArray,\n",
    "        new_benchmarks_by_features: numpy.typing.NDArray,\n",
    "    ) -> numpy.typing.NDArray:\n",
    "        \"\"\"\n",
    "        new_system_by_selected_benchmarks: array where the qth element is the log of the new system's slowdown on the qth selected benchmark\n",
    "        selected_benchmarks_by_features: array where the (q,m)th element is the mth feature of the qth selected benchmark\n",
    "        new_benchmarks_by_features: array where the (p,m)th element is the mth feature of the pth new benchmark\n",
    "\n",
    "        returns an array where the pth element is the log slowdown of the new system on the pth new benchmark\n",
    "        \"\"\"\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
